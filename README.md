# Azure OpenAI Japanese Best Practices

## Goals

- Understand the OpenAI cl100k_base BPE and how it tokenizes Japanese
- Understand the expected/average number of tokens per word
- Understand the ratio of tokens for Japanese and English for the same sentence
- Understand the performance of a tool to chunk text before a text embedding/vector index (ja.microsoft and ja.lucene performance)

## License

The notebooks are MIT license.

The data is public domain CC, see https://tatoeba.org/en/downloads