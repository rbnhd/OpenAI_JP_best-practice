{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MIRACL Benchmark with analyzers\n",
    "\n",
    "This experiment is to compare the performance of the Microsoft and Lucene analyzers with the MIRACL benchmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install datasets pandas azure-identity \"azure-search-documents==11.6.0b1\" azure-cosmos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the MIRACL Corpus (this a dump of a bunch of data from Japanese Wikipedia)\n",
    "import datasets\n",
    "\n",
    "lang='ja'  # or any of the 16 languages\n",
    "miracl_corpus = datasets.load_dataset('miracl/miracl-corpus', lang, cache_dir='.cache', trust_remote_code=True)['train']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Upload the documents in the corpus to Cosmos DB in batches (50 at a time)\n",
    "# This will take hours..\n",
    "from azure.cosmos.aio import CosmosClient\n",
    "from azure.cosmos.partition_key import PartitionKey\n",
    "import os\n",
    "import asyncio\n",
    "\n",
    "# Replace the connection string with your own.\n",
    "client = CosmosClient(os.environ[\"AZURE_COSMOS_URI\"], credential=os.environ[\"AZURE_COSMOS_KEY\"])\n",
    "\n",
    "db = await client.create_database_if_not_exists(id='miracl')\n",
    "# setup container for this sample\n",
    "container = await db.create_container_if_not_exists(id='corpus',\n",
    "                                             partition_key=PartitionKey(path='/docid', kind='Hash'))\n",
    "\n",
    "for i in range(0, 40): # ~270,000 documents\n",
    "   test_corpus = miracl_corpus.shard(1000, i)\n",
    "\n",
    "   for batch in test_corpus.to_pandas(batched=True, batch_size=50):\n",
    "      documents = batch.to_dict(orient='records')\n",
    "      tasks = []\n",
    "      for doc in documents:\n",
    "         doc['id'] = doc['docid'].replace(\"#\", \"i\")\n",
    "         tasks.append(container.upsert_item(doc))\n",
    "      await asyncio.gather(*tasks)\n",
    "      print(f\"Added batch of 50 documents to CosmosDB in batch {i}, last index - {doc['docid']}.\")\n",
    "   print(f\"Added batch {i} to CosmosDB index.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Capture a list of all the documents we did upload with the same sharding criteria as above \"\"\"\n",
    "indexed_docs = []\n",
    "for i in range(0, 40):\n",
    "   test_corpus = miracl_corpus.shard(1000, i)\n",
    "   for batch in test_corpus.to_pandas(batched=True, batch_size=50):\n",
    "      indexed_docs.extend([doc['docid'] for doc in batch.to_dict(orient='records')])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "import os\n",
    "import json\n",
    "\n",
    "token = os.environ[\"HUGGING_FACE_TOKEN\"]\n",
    "lang='ja'  # or any of the 16 languages\n",
    "miracl = datasets.load_dataset('miracl/miracl', lang, use_auth_token=token, cache_dir='.cache')\n",
    "\n",
    "# training set:\n",
    "questions = {}\n",
    "\n",
    "for data in miracl['train']:  # or 'dev', 'testA'\n",
    "  query_id = data['query_id']\n",
    "  query = data['query']\n",
    "  if data['query_id'] not in questions:\n",
    "    questions[data['query_id']] = {'query': data['query'], 'positive_passages': [], 'negative_passages': []}\n",
    "\n",
    "  positive_passages = data['positive_passages']\n",
    "  negative_passages = data['negative_passages']\n",
    "  for entry in positive_passages:\n",
    "    if entry['docid'] in indexed_docs:\n",
    "      questions[data['query_id']]['positive_passages'].append(entry['docid'])\n",
    "  for entry in negative_passages:\n",
    "    if entry['docid'] in indexed_docs:\n",
    "      questions[data['query_id']]['negative_passages'].append(entry['docid'])\n",
    "\n",
    "# Clean up the questions and remove any that don't have positive passages\n",
    "searchable_questions = {}\n",
    "for query_id, question in questions.items():\n",
    "  if len(question['positive_passages']) > 0:\n",
    "    searchable_questions[query_id] = question\n",
    "\n",
    "with open('data/miracl_questions.json', 'w') as f:\n",
    "  json.dump(searchable_questions, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(miracl['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.identity.aio import DefaultAzureCredential\n",
    "from azure.search.documents.aio import SearchClient\n",
    "from azure.search.documents.indexes.aio import SearchIndexClient, SearchIndexerClient\n",
    "from azure.search.documents.indexes.models import (\n",
    "    SimpleField,\n",
    "    SearchableField,\n",
    "    SearchIndex,\n",
    "    SearchIndexer,\n",
    "    SearchFieldDataType,\n",
    ")\n",
    "from azure.core.exceptions import ResourceNotFoundError\n",
    "import os\n",
    "ANALYSER = \"ja.microsoft\"\n",
    "\n",
    "service_endpoint = os.getenv(\"AZURE_SEARCH_ENDPOINT\")\n",
    "index_name = 'test-miracl-index-ja-microsoft'\n",
    "indexer_name = 'test-miracl-indexer-ja-microsoft'\n",
    "azure_cred = DefaultAzureCredential()\n",
    "\n",
    "search_client = SearchClient(service_endpoint, index_name, azure_cred)\n",
    "index_client = SearchIndexClient(service_endpoint, azure_cred)\n",
    "indexer_client = SearchIndexerClient(service_endpoint, azure_cred)\n",
    "\n",
    "async def create_miracl_corpus_index(name):\n",
    "    try:\n",
    "        if await index_client.get_index(name):\n",
    "            return\n",
    "    except ResourceNotFoundError:\n",
    "        pass\n",
    "    fields = [\n",
    "        SimpleField(name=\"id\", type=SearchFieldDataType.String, key=True),\n",
    "        SimpleField(name=\"docid\", type=SearchFieldDataType.String),\n",
    "        SimpleField(name=\"title\", type=SearchFieldDataType.String),\n",
    "        SearchableField(name=\"text\", type=SearchFieldDataType.String, analyzer_name=ANALYSER),\n",
    "    ]\n",
    "    index = SearchIndex(\n",
    "        name=name,\n",
    "        fields=fields)\n",
    "    result = await index_client.create_index(index)\n",
    "    return result\n",
    "\n",
    "async def create_indexer(name, index_name):\n",
    "    try:\n",
    "        if await indexer_client.get_indexer(name):\n",
    "            return\n",
    "    except ResourceNotFoundError:\n",
    "        pass\n",
    "    # Create an indexer\n",
    "    indexer_name = f\"{name}-indexer\"\n",
    "\n",
    "    indexer = SearchIndexer(\n",
    "        name=indexer_name,\n",
    "        description=\"Indexer to index documents and generate embeddings\",\n",
    "        # skillset_name=f\"{name}-skillset\",\n",
    "        target_index_name=index_name,\n",
    "        data_source_name=f\"miracl-cosmos\",\n",
    "    )\n",
    "\n",
    "    return await indexer_client.create_or_update_indexer(indexer)\n",
    "\n",
    "await create_miracl_corpus_index(index_name)\n",
    "await create_indexer(indexer_name, index_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.identity.aio import DefaultAzureCredential\n",
    "from azure.search.documents.aio import SearchClient\n",
    "\n",
    "import os\n",
    "ANALYSER = \"ja.microsoft\"\n",
    "\n",
    "service_endpoint = os.getenv(\"AZURE_SEARCH_ENDPOINT\")\n",
    "azure_cred = DefaultAzureCredential()\n",
    "\n",
    "search_clients = {\n",
    "  \"ja-microsoft\": SearchClient(service_endpoint, 'test-miracl-index-ja-microsoft', azure_cred),\n",
    "  \"ja-lucene\": SearchClient(service_endpoint, 'test-miracl-index-ja-lucene', azure_cred),\n",
    "  \"no-analyzer\": SearchClient(service_endpoint, 'test-miracl-index-no-analyzer', azure_cred)\n",
    "}\n",
    "\n",
    "with open('data/miracl_questions.json', 'r') as f:\n",
    "  questions = json.load(f)\n",
    "\n",
    "results = {}\n",
    "\n",
    "for query_id, query in questions.items():\n",
    "  print(f\"Query: {query['query']}\")\n",
    "  results[query_id] = {\n",
    "    \"query\": query['query'],\n",
    "    \"positive_passages\": query['positive_passages'],\n",
    "    \"negative_passages\": query['negative_passages'],\n",
    "    \"ja-lucene-results\": [],\n",
    "    \"ja-microsoft-results\": [],\n",
    "    \"no-analyzer-results\": []\n",
    "  }\n",
    "  for analyzer, client in search_clients.items():\n",
    "    response = await search_client.search(\n",
    "      search_text=query['query'],\n",
    "      query_type=\"semantic\",\n",
    "      semantic_configuration_name=\"miracl-semantic\",\n",
    "      query_answer=\"extractive\",\n",
    "      query_answer_count=3,\n",
    "      query_caption=\"extractive\",\n",
    "      query_language=\"ja-JP\")\n",
    "    answers = await response.get_answers()\n",
    "    matches = [answer.as_dict()['key'].replace('i', '#') for answer in answers]\n",
    "    results[query_id][f\"{analyzer}-results\"] = matches\n",
    "\n",
    "with open('miracl-results.json', 'w') as f:\n",
    "  json.dump(results, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
